{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "714c3d21-ffec-4a2d-a61b-99e171f56698",
   "metadata": {},
   "source": [
    "---\n",
    "title: NetOps\n",
    "subject: Tutorial\n",
    "subtitle: Notebook for UAV Cal/Val experiment in El Socorro\n",
    "short_title: UAV Cal/Val experiment\n",
    "authors:\n",
    "  - name: Vicente Burchard-Levine\n",
    "    affiliations:\n",
    "    - Instituto de Ciencias Agrarias, ICA\n",
    "    - CSIC\n",
    "    orcid: 0000-0003-0222-8706\n",
    "    email: vburchard@ica.csic.es\n",
    "  - name: Juan José Peón\n",
    "    affiliations:\n",
    "    - Área de Sistemas de Teledetección\n",
    "    - INTA\n",
    "    orcid: 000\n",
    "    email: jpeogar@inta.es\n",
    "  - name: Héctor Nieto\n",
    "    affiliations:\n",
    "      - Instituto de Ciencias Agrarias, ICA\n",
    "      - CSIC\n",
    "    orcid: 0000-0003-4250-6424\n",
    "    email: hector.nieto@ica.csic.es\n",
    "  - name: Your names\n",
    "    affiliations:\n",
    "    - Your affiliation\n",
    "    - Acronymn\n",
    "    orcid: your orcid\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f238723-c9e1-43d2-84de-ffaa6f3729a5",
   "metadata": {},
   "source": [
    "# Summary\n",
    "This notebook will perform a step-by-step guide on how to perform a calibration and valitation (Cal/Val) of different UAV-based sensors using vicarious in-situ measurements during UAV overpasses.\n",
    "\n",
    "The data were collected on September 19th, 2022, at the El Socorro experimental vineyard farm managed by IMIDRA during PTI TELEDETECT workshop.\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "0. [Mount dataset from Google Drive](#connect-to-dataset-in-google-drive)\n",
    "1. [Import Libraries](#import-libraries)\n",
    "1. [Image selection](#select-and-image-to-work-with)\n",
    "2. [Visualize and preprocess insitu ASD data](#preprocess-asd-data)\n",
    "3. [Extracting UAV data over reference panels](#extract-uav-values-over-reference-panels)\n",
    "4. [Develop empirical line](#develop-empirical-line)\n",
    "5. [Calibrate and validate imagery based on empirical line](#Calibrate-image-with-developed-empirical-model)\n",
    "\n",
    "> **Hint**: once each section is read, run the jupyter code cell underneath (marked as `[]`) by clicking the icon `Run`, or pressing the keys SHIFT+ENTER of your keyboard.\n",
    "\n",
    "\n",
    "> **Note**: No programming skills are required to follow up this notebook. However, if you feel comfortable with Python, you are very welcome to edit the code and provide suggestions in this collaborative framework.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "Code adapted from a [AET 2024](http://eo.csic.es/aet2024) course led by Juan José Peón | Área de Sistemas de Teledetección | Instituto Nacional de Técnica Aeroespacial (INTA) | jpeogar@inta.es\n",
    "\n",
    "Original code available here: https://colab.research.google.com/drive/14GBdZ9rsC3nep4FKEVtSN-1VdcnB6kca\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0964f93c-c7cc-4227-a9ee-55551cf91929",
   "metadata": {},
   "source": [
    "# Install libraries and dependencies\n",
    "\n",
    "First step is to make sure you have all the dependencies. Refer to the readme file to install all dependencies. It also recommended to create a conda environment or make sure all libraries necessary are correctly installed.\n",
    "\n",
    "## Installation\n",
    "\n",
    "You should have these programs installed:\n",
    "\n",
    "* Python and/or [Anaconda](https://www.anaconda.com/download/success). \n",
    "\n",
    "Install the requirements either with conda/mamba:\n",
    "\n",
    "`mamba env create -f environment.yml`\n",
    "\n",
    "or\n",
    "\n",
    "`conda env create -f environment.yml`\n",
    "\n",
    "or \n",
    "\n",
    "Make sure you have the required libraries installed:\n",
    "- jupyter\n",
    "- notebook\n",
    "- jupyterlab\n",
    "- jupyter-book\n",
    "- gdal\n",
    "- numpy\n",
    "- scipy\n",
    "- pandas\n",
    "- matplotlib\n",
    "- geopandas\n",
    "- pathlib\n",
    "- scikit-learn\n",
    "- mystmd\n",
    "- jupyterlab-myst\n",
    "\n",
    "\n",
    "## Run the interactive book\n",
    "Run the following command to initialize the book:\n",
    "\n",
    "1. Activate python environment \n",
    "\n",
    "`conda activate calval-netops`\n",
    "\n",
    "2. Initialize jupyter notebook\n",
    "  \n",
    "`jupyter notebook uav_calval_socorro.ipynb`\n",
    "\n",
    "or \n",
    "\n",
    "`jupyter lab uav_calval_socorro.ipynb`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0bef7c-f789-4cdb-a272-683a5d4b1e74",
   "metadata": {},
   "source": [
    "# Import Libraries\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82fd60b-ca79-4c9b-8d83-08cd99ade1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import zipfile\n",
    "import getpass\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from osgeo import gdal\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from ipywidgets import interact, interactive, fixed, widgets\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import os\n",
    "import scipy.stats as st\n",
    "import gc\n",
    "import requests\n",
    "import rasterstats\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "print('libraries imported correctly!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcced7e-1ce2-49a8-a3b6-4eda7174dd2c",
   "metadata": {},
   "source": [
    "## Dataset summary\n",
    "A total of **10 UAV overpasses** were performed on September 19th, 2022, which included **6 multispectral** flights, **3 thermal infrared** flights, and **1 hyperspectral** flight.\n",
    "\n",
    "See table below for a summary of UAV dataset acquired:\n",
    "\n",
    "|Sensor|Sensor Type |Number of bands|Group |Flight Time (UTC)   \n",
    "| :---     | :--- | :---  | :---  | :---  \n",
    "| P4M      |Multi/VNIR | 5|ICMAN  | 08:43\n",
    "| P4M      |Multi/VNIR | 5|ICMAN  | 09:14\n",
    "| Sequoia+ |Multi/VNIR | 4|ICA  | 09:42\n",
    "| Micasense|Multi/VNIR | 10|ICMAN  | 10:24\n",
    "| Micasense|Multi/VNIR | 10|ICMAN  | 10:51\n",
    "| P4M|Multi/VNIR | 5|GEOINCA  | 11:29\n",
    "| H20T|TIR| 1|ICA  | 09:42\n",
    "| M2EA|TIR| 1|ICMAN  | 11:30\n",
    "| M2EA|TIR| 1|ICMAN  | 11:40\n",
    "| Cubert S185|Hyper/VNIR| 125|EBD  | 11:57\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec9a7bb-958f-4a09-8f32-9f47cc033a1f",
   "metadata": {},
   "source": [
    "# Select and image to work with\n",
    "\n",
    "First we will select from {ref}`images-description` the images we will work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac30c3f6-55c4-4d91-944b-7ea78e6bc6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_image = widgets.Dropdown(\n",
    "    options=[('P4M at 08:43', \"P4M_ICMAN_0843\"), ('P4M at 09:14', \"P4M_ICMAN_0914\"),\n",
    "             ('Sequoia+ at 09:42', \"Sequoia_ICA_0942\"),\n",
    "             ('Micasense at 09:58', \"Micasense_ICMAN_0958\"), ('Micasense at 10:49', \"Micasense_ICMAN_1049\"),\n",
    "             ('P4M at 11:29', \"P4M_GEOINCA_1129\"), ('Cubert at 11:57', \"Cubert_EBD_1157\")\n",
    "            ],\n",
    "    value=\"Sequoia_ICA_0942\",\n",
    "    description='Image:',\n",
    ")\n",
    "\n",
    "display(Markdown(\"## Select an image\"), w_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfdd98b-e8dc-4c47-bad9-3a8fdc046ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select orthomosaico or tiles\n",
    "w_image_type = widgets.Dropdown(\n",
    "    options=[('Orthomosaic', \"Mosaic\"), ('Individual Tile', \"Panels\")\n",
    "            ],\n",
    "    value=\"Mosaic\",\n",
    "    description='Image:',\n",
    ")\n",
    "\n",
    "display(Markdown(\"## Mosaic or tile?\"), w_image_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c55d838-0cfc-47bb-be8d-413196499714",
   "metadata": {},
   "source": [
    "## Set up working directory and get sensor metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e15f84-0c01-4680-b0cc-df9e625bfa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set work directory (convert data directory as a Path object)\n",
    "workdir = Path()\n",
    "\n",
    "# set up out directory \n",
    "outdir = workdir / 'outputs'\n",
    "# add dataset directory\n",
    "datadir = workdir / 'dataset'\n",
    "# We get the image information from the widget selection\n",
    "sensor_name, sensor_group, sensor_time = w_image.value.split(\"_\")\n",
    "\n",
    "if sensor_name == 'Cubert':\n",
    "  # folder with hyperspectral imagery\n",
    "  uav_base_dir = datadir / 'dataset' / 'uav_imagery' / 'hyper'\n",
    "\n",
    "else:\n",
    "  # folder with multispetral imagery\n",
    "  uav_base_dir = datadir / 'dataset' / 'uav_imagery' / 'multi'\n",
    "\n",
    "if w_image_type.value == 'Panels':\n",
    "  # directory to mosaic\n",
    "  uav_dir = uav_base_dir / f\"{sensor_name}_{sensor_group}\" / 'tiles_panels'\n",
    "\n",
    "  # get tile file list\n",
    "  tile_files = list(uav_dir.glob(f'{w_image_type.value}_REF_{sensor_name}_{sensor_group}_*.tif'))\n",
    "\n",
    "  # create option list based on available tiles\n",
    "  option_list = []\n",
    "  for file in tile_files:\n",
    "    option_i = (file.name, file)\n",
    "    option_list.append(option_i)\n",
    "\n",
    "\n",
    "  #select orthomosaico or tiles\n",
    "  w_tile_name = widgets.Dropdown(\n",
    "      options=option_list,\n",
    "      value=option_list[0][1],\n",
    "      description='filename:',\n",
    "  )\n",
    "\n",
    "  #option_list\n",
    "  display(Markdown(\"## Choose which tile to process\"), w_tile_name)\n",
    "\n",
    "else:\n",
    "  # directory to mosaic\n",
    "  uav_dir = uav_base_dir / f\"{sensor_name}_{sensor_group}\" / 'mosaic'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b8dc7-f978-4d95-9529-c2a5f14a48d0",
   "metadata": {},
   "source": [
    "## Visualize UAV image\n",
    "We will now visualize the image using false color image composite (R: NIR, G: Red, B: Green). For this, we incorporate the sensor description and metadata in a dictionary variable, including band center wavelength and width.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd647512-606b-407d-8cb9-8a1a116dca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary with relevant band info from each sensor\n",
    "sensor_dict = {\"Sequoia\": {'center_wl':[550, 660, 735, 790],\n",
    "                           'bandwidth':[40,40,10,40],\n",
    "                           'false_color_bands':[4, 2, 1]}, # [nir, red, green]\n",
    "\n",
    "               \"Micasense\":{'center_wl':[444, 475, 531, 560, 650, 668, 705, 717, 740, 842],\n",
    "                            'bandwidth':[28, 32, 14, 27, 16, 14, 10, 12, 18, 57],\n",
    "                            'false_color_bands':[10, 5, 4]}, # [nir, red, green]\n",
    "\n",
    "               \"P4M\":{'center_wl':[450, 560, 650, 730, 840],\n",
    "                      'bandwidth':[16, 16, 16, 16, 26],\n",
    "                      'false_color_bands':[5, 3, 2]},\n",
    "\n",
    "               \"Cubert\":{'center_wl':list(range(450, 947, 4)),\n",
    "                         'bandwidth':[3.96344384, 4.22669042, 4.48993699, 4.74254005, 4.98598345, 5.22071147, 5.44653427, 5.66433633, 5.87442525, 6.07733135,\n",
    "                                      6.27352687, 6.46250939, 6.64543238, 6.82258481, 6.99388625, 7.1595225, 7.32003116, 7.47551465, 7.62647149, 7.77271727,\n",
    "                                      7.91450516, 8.19529191, 8.69417279, 9.17985398, 9.65092299, 10.108535, 10.5537396, 10.987298, 11.4081975, 11.8182273,\n",
    "                                      12.2163699, 12.6047879, 12.9836208, 13.3515169, 13.710384, 14.0604483, 14.401957, 14.7351589, 15.0597232, 15.3761906,\n",
    "                                      15.6847689, 15.9862039, 16.2807826, 16.5685624, 16.8492932, 17.1237615, 17.3924124, 17.6541616, 17.9099653, 18.1601686,\n",
    "                                      18.4049445, 18.6445771, 18.8793717, 19.1088194, 19.3325072, 19.5520081, 19.7675729, 19.9782123, 20.1836628, 20.3856621,\n",
    "                                      20.5839564, 20.7768683, 20.9669533, 21.1533516, 21.3350125, 21.5144747, 21.6891907, 21.8610244, 22.0300313, 22.1947156,\n",
    "                                      22.3581132, 22.5158792, 22.6728688, 22.8250268, 22.9761498, 23.1228934, 23.2685793, 23.409865, 23.5505148, 23.686469,\n",
    "                                      23.8224233, 23.9533522, 24.0840902, 24.2110763, 24.3366143, 24.460163, 24.5805574, 24.7009518, 24.8165964, 24.9320029,\n",
    "                                      25.0453379, 25.1557019, 25.2660659, 25.3727363, 25.4782084, 25.5836805, 25.6843936, 25.7849903, 25.8852887, 25.9811129,\n",
    "                                      26.076937, 26.1727435, 26.2638769, 26.3550104, 26.4461439, 26.5336399, 26.6201551, 26.7066702, 26.7913548, 26.8732907,\n",
    "                                      26.9552267, 27.0371627, 27.1154286, 27.192903, 27.2703774, 27.3476769, 27.420713, 27.4937491, 27.5667852, 27.6397066,\n",
    "                                      27.7083809, 27.7770553, 27.8457297, 27.9144041, 27.9830785],\n",
    "                         'false_color_bands':[121, 51, 26]} # [nir, red, green]\n",
    "              }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690dfedb-5312-4f8c-8985-225931a6ec38",
   "metadata": {},
   "source": [
    "Now we will visualize the image as two panel figure. **Left panel:** mosaic and **Right panel:** zoomed over the reference panels\n",
    "\n",
    "\n",
    "> **Note:** it might take a few moments for images to visualize, especially those with more bands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d47e1c-fe2b-4495-9e3d-fcf12364ca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapefile directory\n",
    "vector_dir = datadir /'dataset'/ 'vector_data'\n",
    "\n",
    "# panel outline shapefile\n",
    "panels_file = vector_dir/'panels_borders.geojson'\n",
    "\n",
    "# open as geopandas dataframe\n",
    "panels_gdf = gpd.read_file(panels_file)\n",
    "\n",
    "# sensor metadata\n",
    "sensor_band_info = sensor_dict[sensor_name]\n",
    "\n",
    "# plot for individual tile\n",
    "if w_image_type.value == 'Panels':\n",
    "  # directory to mosaic\n",
    "  mosaic_file = w_tile_name.value\n",
    "  filename = mosaic_file.name\n",
    "  # update sensor time with tile time\n",
    "  sensor_time = filename.split('_')[-2]\n",
    "\n",
    "  # display image metadata\n",
    "  display((Markdown(f\"**Reading information from {sensor_name} sensor owned by {sensor_group}. Individual tile: {filename}**\")))\n",
    "  # open as GDAL object\n",
    "  fid = gdal.Open(str(mosaic_file))\n",
    "\n",
    "  # get number of bands\n",
    "  num_bands = fid.RasterCount\n",
    "\n",
    "  # get geotransform and other metadata\n",
    "  geotransform = fid.GetGeoTransform()\n",
    "  minx, maxy = geotransform[0], geotransform[3]\n",
    "  maxx = minx + geotransform[1] * fid.RasterXSize\n",
    "  miny = maxy + geotransform[5] * fid.RasterYSize\n",
    "\n",
    "  # Read specific bands (4=NIR, 3=Red-Edge,2=Red and 1=Green)\n",
    "  nir_band = sensor_band_info['false_color_bands'][0]\n",
    "  red_band = sensor_band_info['false_color_bands'][1]\n",
    "  green_band = sensor_band_info['false_color_bands'][2]\n",
    "\n",
    "  if sensor_name == 'Cubert' or (sensor_name == 'P4M' and sensor_group=='ICMAN'):\n",
    "    nir_ar = fid.GetRasterBand(nir_band).ReadAsArray()/10000  # Near-Infrared\n",
    "    red_ar = fid.GetRasterBand(red_band).ReadAsArray()/10000  # Red\n",
    "    green_ar = fid.GetRasterBand(green_band).ReadAsArray()/10000  # Green\n",
    "  else:\n",
    "    nir_ar = fid.GetRasterBand(nir_band).ReadAsArray()  # Near-Infrared\n",
    "    red_ar = fid.GetRasterBand(red_band).ReadAsArray()  # Red\n",
    "    green_ar = fid.GetRasterBand(green_band).ReadAsArray()  # Green\n",
    "\n",
    "  # Stack the bands to obtain false colour image: R=NIR, G=Red, B=Green\n",
    "  false_color_image = np.dstack((nir_ar, red_ar, green_ar))\n",
    "\n",
    "  # delete array to avoid overuse of RAM\n",
    "  del nir_ar, red_ar, green_ar\n",
    "  del fid\n",
    "  # make side by side false colour figure\n",
    "  fig, ax = plt.subplots(1,1, figsize=(14,7))\n",
    "\n",
    "  # whole study area\n",
    "  ax.imshow(false_color_image, extent=[minx, maxx, miny, maxy])\n",
    "  # overlay reference panel borders\n",
    "  panels_gdf.plot(ax=ax, facecolor='none', edgecolor='indianred', linewidth=1)\n",
    "\n",
    "  ax.set_title('False Colour (NIR, RED, GREEN): Study Site')\n",
    "  # 4. Annotate the plot with labels from the GeoDataFrame\n",
    "  for idx, row in panels_gdf.iterrows():\n",
    "      # Get the centroid of the geometry (or use point coordinates directly)\n",
    "      if row.geometry.geom_type == 'Point':\n",
    "          x, y = row.geometry.x, row.geometry.y  # For points\n",
    "      else:\n",
    "          x, y = row.geometry.centroid.x, row.geometry.centroid.y  # For polygons\n",
    "\n",
    "      if row['code'][:-1] == 'INTA':\n",
    "          # Annotate the map with the 'name' field (or any other attribute)\n",
    "          ax.annotate(text=row['code'], xy=(x, y),  xytext=(x, y+1.6), xycoords='data',\n",
    "                      fontsize=5, ha='center', color='white')\n",
    "      elif row['code'][:-1] == 'IAS':\n",
    "          # Annotate the map with the 'name' field (or any other attribute)\n",
    "          ax.annotate(text=row['code'], xy=(x, y),  xytext=(x, y+1.2), xycoords='data',\n",
    "                      fontsize=6, ha='center', color='white')\n",
    "      else:\n",
    "          # Annotate the map with the 'name' field (or any other attribute)\n",
    "          ax.annotate(text=row['code'], xy=(x, y),  xytext=(x, y+0.7), xycoords='data',\n",
    "                      fontsize=6, ha='center', color='white')\n",
    "  plt.show()\n",
    "\n",
    "# plot for mosaic\n",
    "else:\n",
    "  # display image metadata\n",
    "  display((Markdown(f\"**Reading information from {sensor_name} sensor owned by {sensor_group} and acquired at {sensor_time[:2]}:{sensor_time[2:]}**\")))\n",
    "\n",
    "  # directory to mosaic\n",
    "  uav_dir = uav_base_dir / f\"{sensor_name}_{sensor_group}\" / 'mosaic'\n",
    "\n",
    "  # get orthomosaic file\n",
    "  mosaic_file = uav_dir / f'Mosaic_REF_{w_image.value}.tif'\n",
    "\n",
    "  # open as GDAL object\n",
    "  fid = gdal.Open(str(mosaic_file))\n",
    "\n",
    "  # get number of bands\n",
    "  num_bands = fid.RasterCount\n",
    "\n",
    "  # get geotransform and other metadata\n",
    "  geotransform = fid.GetGeoTransform()\n",
    "  minx, maxy = geotransform[0], geotransform[3]\n",
    "  maxx = minx + geotransform[1] * fid.RasterXSize\n",
    "  miny = maxy + geotransform[5] * fid.RasterYSize\n",
    "\n",
    "  # Read specific bands (4=NIR, 3=Red-Edge,2=Red and 1=Green)\n",
    "  nir_band = sensor_band_info['false_color_bands'][0]\n",
    "  red_band = sensor_band_info['false_color_bands'][1]\n",
    "  green_band = sensor_band_info['false_color_bands'][2]\n",
    "\n",
    "  nir_ar = fid.GetRasterBand(nir_band).ReadAsArray()  # Near-Infrared\n",
    "  red_ar = fid.GetRasterBand(red_band).ReadAsArray()  # Red\n",
    "  green_ar = fid.GetRasterBand(green_band).ReadAsArray()  # Green\n",
    "\n",
    "  # Stack the bands to obtain false colour image: R=NIR, G=Red, B=Green\n",
    "  false_color_image = np.dstack((nir_ar, red_ar, green_ar))\n",
    "\n",
    "  # delete array to avoid overuse of RAM\n",
    "  del nir_ar, red_ar, green_ar\n",
    "  del fid\n",
    "  # make side by side false colour figure\n",
    "  fig, axes = plt.subplots(1,2, figsize=(14,14))\n",
    "\n",
    "  # whole study area\n",
    "  ax1 = axes[0]\n",
    "  ax1.imshow(false_color_image, extent=[minx, maxx, miny, maxy])\n",
    "  # overlay reference panel borders\n",
    "  panels_gdf.plot(ax=ax1, facecolor='none', edgecolor='indianred', linewidth=1)\n",
    "\n",
    "  ax1.set_title('False Colour (NIR, RED, GREEN): Study Site')\n",
    "\n",
    "  # zoom to reference panels\n",
    "  ax2 = axes[1]\n",
    "  ax2.imshow(false_color_image, extent=[minx, maxx, miny, maxy])\n",
    "  # overlay reference panel borders\n",
    "  panels_gdf.plot(ax=ax2, facecolor='none', edgecolor='indianred', linewidth=1)\n",
    "  # 4. Annotate the plot with labels from the GeoDataFrame\n",
    "  for idx, row in panels_gdf.iterrows():\n",
    "      # Get the centroid of the geometry (or use point coordinates directly)\n",
    "      if row.geometry.geom_type == 'Point':\n",
    "          x, y = row.geometry.x, row.geometry.y  # For points\n",
    "      else:\n",
    "          x, y = row.geometry.centroid.x, row.geometry.centroid.y  # For polygons\n",
    "\n",
    "      if row['code'][:-1] == 'INTA':\n",
    "          # Annotate the map with the 'name' field (or any other attribute)\n",
    "          ax2.annotate(text=row['code'], xy=(x, y),  xytext=(x, y+1.6), xycoords='data',\n",
    "                      fontsize=5, ha='center', color='white')\n",
    "      elif row['code'][:-1] == 'IAS':\n",
    "          # Annotate the map with the 'name' field (or any other attribute)\n",
    "          ax2.annotate(text=row['code'], xy=(x, y),  xytext=(x, y+1.2), xycoords='data',\n",
    "                      fontsize=6, ha='center', color='white')\n",
    "      else:\n",
    "          # Annotate the map with the 'name' field (or any other attribute)\n",
    "          ax2.annotate(text=row['code'], xy=(x, y),  xytext=(x, y+0.7), xycoords='data',\n",
    "                      fontsize=6, ha='center', color='white')\n",
    "\n",
    "  ax2.set_title('False Colour (NIR, RED, GREEN): Reference Panels')\n",
    "  # set xy lim to zoom to panels, change for different zoom extent\n",
    "  ax2.set_xlim(468115,468140)\n",
    "  ax2.set_ylim(4442870,4442890)\n",
    "  plt.show()\n",
    "gc.collect()\n",
    "del false_color_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b45f3cf-8d54-425f-acee-113d54f997a7",
   "metadata": {},
   "source": [
    "# Preprocess ASD data\n",
    "\n",
    "ASD measurements were acquired over the references panels visible in the right panel of the above figure.\n",
    "\n",
    "Three different rounds of measurements were acquired (R1, R2 and R3) over three different panel groups: **INTA, ICA and IAS**.\n",
    "\n",
    "Each panel groups has different number of panels that roughly range from white to black.\n",
    "\n",
    "**INTA** has *3 panels*, **ICA** has *7 panels* and **IAS** has *4 panels*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7f6661-b728-4996-b179-1d79f7d61ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get asd file directory\n",
    "asd_file = datadir / 'dataset' / 'insitu' / 'ASDFieldSpec3_16120_SpecLab' / 'socorro_asd_panels_mean_all.csv'\n",
    "\n",
    "# open asd file as a pandas directory\n",
    "asd_df = pd.read_csv(asd_file)\n",
    "\n",
    "print(f'Example of ASD dataset structure\\n')\n",
    "# show first five rows\n",
    "print(asd_df.head())\n",
    "\n",
    "# get wavelengths as series\n",
    "wl_asd = asd_df[\"Wavelength\"].values\n",
    "\n",
    "# get id of all panels (omiting the first column which is the wavelength)\n",
    "id_panel = asd_df.columns[1:]\n",
    "\n",
    "# get panel ID to identify the panel type (i.e. INTA1, INTA2, INTA3 etc) i.e. remove round number 'R1', 'R2' etc\n",
    "id_panel_type = id_panel.str.split('_').map(lambda x: x[0])\n",
    "# get unique values of ID\n",
    "panels_unique = id_panel_type.unique()\n",
    "\n",
    "print(f'\\nPanel groups and number:\\n{list(panels_unique)}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8482d158-c16d-4732-8179-9365e6e044dc",
   "metadata": {},
   "source": [
    "## Visualize ASD data\n",
    "\n",
    "Plot ASD data from all rounds (R1, R2, and R3) for each group of panels (INTA, ICA, and IAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f326f-94e7-4e97-ab02-4fe31381705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the panels from different groups\n",
    "panel_groups = ['INTA', 'ICA', 'IAS']\n",
    "\n",
    "# create 3x1 plot with each panel group\n",
    "fig, axes = plt.subplots(3,1, figsize=(12,18))\n",
    "i = 0\n",
    "for group in panel_groups:\n",
    "    # select all panels related to this group (INTA, ICA or IAS)\n",
    "    groups_select = list(panels_unique[panels_unique.str.contains(group)])\n",
    "    # sort from panel 1 to 4\n",
    "    groups_select.sort()\n",
    "\n",
    "    # initialize axis\n",
    "    ax = axes[i]\n",
    "    ax.set_title(f'{group} panels', fontsize=14)\n",
    "    ax.set_xlabel('Wavelength (nm)', fontsize=12)\n",
    "    ax.set_xlim(330, 2520)\n",
    "    ax.set_ylabel('Reflectance (-)', fontsize=12)\n",
    "    ax.set_ylim(0, 1.2)\n",
    "    ax.grid(True)\n",
    "\n",
    "    # create light to dark gradient depending on number of panels\n",
    "    color_gradient = np.linspace(0.8, 0, len(groups_select)).astype(str)\n",
    "    # plot for each panel number\n",
    "    for n, g in enumerate(groups_select):\n",
    "      cols = id_panel[id_panel.str.contains(g)]\n",
    "      panel_number = asd_df[cols]\n",
    "      # plot each of the spectra (each round)\n",
    "      for col in panel_number.columns:\n",
    "        ax.plot(wl_asd, panel_number[col].values, label=g, color=color_gradient[n])\n",
    "    i = i + 1\n",
    "\n",
    "# create legend for each subplot\n",
    "for ax in axes:\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "    # Create a dictionary to remove duplicates (preserves the first occurrence)\n",
    "    unique = dict(zip(labels, handles))\n",
    "\n",
    "    # Add the legend with only the unique panel labels and color\n",
    "    ax.legend(unique.values(), unique.keys(), loc='upper left', ncols = len(groups_select))\n",
    "\n",
    "gc.collect()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7667419c-d1c5-40fa-b486-b5cefda0c29d",
   "metadata": {},
   "source": [
    "## Convolve ASD spectra using the spectral response function (SRF)\n",
    "\n",
    "We need to convolve the ASD measurements (400-2500nm) to the spectral response function (SRF) of the sensor. If SRF curve is available, the script will use that. If not, we assume a gaussian function using band center wavelength and bandwidth.\n",
    "\n",
    "> **Note:** only Sequoia and Cubert have a SRF file available for the moment.\n",
    "\n",
    "### Plot sensor spectral response function (SRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df51309-f0e8-46f6-8c39-da71d661105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectral response function (SRF) file\n",
    "display(Markdown(f\"**{sensor_name}_{sensor_group}**\"))\n",
    "\n",
    "# try to find SRF .txt file\n",
    "srf_dir = uav_base_dir / f\"{sensor_name}_{sensor_group}\"\n",
    "# looking for SRF in UAV base directory with certain format\n",
    "srf_file_list = list(srf_dir.glob(f'SRF_{sensor_name}*.txt'))\n",
    "\n",
    "# if SRF does not exists assume gaussian response over band center/width\n",
    "if len(srf_file_list) == 0:\n",
    "    # Define the Gaussian function\n",
    "    def gaussian(x, A, mu, sigma):\n",
    "        return A * np.exp(- (x - mu)**2 / (2 * sigma**2))\n",
    "\n",
    "    # if SRF does not exists assume gaussian response over band center/width\n",
    "    srf_dict = {'Wavelength_nm': np.arange(350,2501)}\n",
    "    sensor_center_wl = sensor_dict[sensor_name]['center_wl']\n",
    "    sensor_bandwidths = sensor_dict[sensor_name]['bandwidth']\n",
    "    for n, band in enumerate(sensor_center_wl):\n",
    "        # bandwidth, in this case, refers to the Full Width at Half Maximum (FWHM)\n",
    "        FWHM = sensor_bandwidths[n]\n",
    "        sigma = FWHM/(2*np.sqrt(2*np.log(2)))\n",
    "        band_response = gaussian(srf_dict['Wavelength_nm'], 1, band, sigma)\n",
    "        srf_dict[str(band)] = band_response\n",
    "\n",
    "    srf_df = pd.DataFrame(srf_dict)\n",
    "\n",
    "else:\n",
    "    # use SRF file to plot curves\n",
    "    srf_file = srf_file_list[0]\n",
    "    # open as pandas dataframe\n",
    "    srf_df = pd.read_csv(srf_file, sep = '\\t')\n",
    "\n",
    "band_names = srf_df.columns[1:]\n",
    "\n",
    "# plot spectral response function\n",
    "colormap = plt.cm.rainbow # Choose a colormap\n",
    "colors = [colormap(x / (len(band_names) - 1)) for x in range(len(band_names))]\n",
    "\n",
    "# Show spectral response function (SRF) curves\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.title(f'Spectral Response Function (SRF) - {sensor_name}', fontsize=14)\n",
    "plt.xlabel('Wavelength (nm)', fontsize=12)\n",
    "plt.xlim(400, 1000)\n",
    "plt.ylabel('Relative Response (-)', fontsize=12)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "i = 0\n",
    "for band in band_names:\n",
    "    plt.plot(srf_df['Wavelength_nm'], srf_df[band], color=colors[i], label = f'{str(band)}nm')\n",
    "    i += 1\n",
    "if sensor_name != 'Cubert':\n",
    "  plt.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eb79c6-0548-4752-a173-a346fc35cca4",
   "metadata": {},
   "source": [
    "### Save convolved ASD data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bbc4a9-0b7d-47e0-ad56-9a8b938a592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty dictionary to store results\n",
    "asd_convolved_dict = {'panels': []}\n",
    "\n",
    "# go through all panels (ICA1, ICA2 etc)\n",
    "for panel in id_panel:\n",
    "    asd_data = asd_df[panel]\n",
    "    # add panel id to output dictonary\n",
    "    asd_convolved_dict['panels'].append(panel)\n",
    "    # for each band, apply SRF on ASD spectra\n",
    "    for band in band_names:\n",
    "        asd_band = np.sum(asd_data * srf_df[band])/np.sum(srf_df[band])\n",
    "        # store result in output dictionary\n",
    "        if band in asd_convolved_dict:\n",
    "            asd_convolved_dict[band].append(asd_band)\n",
    "        else:\n",
    "            asd_convolved_dict[band] = []\n",
    "            asd_convolved_dict[band].append(asd_band)\n",
    "\n",
    "# convert output dictionary into pandas dataframe\n",
    "asd_convolved_df = pd.DataFrame(asd_convolved_dict)\n",
    "asd_convolved_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9adc14b-2896-479b-8f8b-598cf49977a5",
   "metadata": {},
   "source": [
    "## Plot convolved ASD data over reference panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3d723-6fd8-4752-90f7-24e758905bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get center wl for each band\n",
    "sensor_band_center = sensor_dict[sensor_name]['center_wl']\n",
    "\n",
    "# create 3x1 plot with each panel group \n",
    "fig, axes = plt.subplots(3,1, figsize=(12,18))\n",
    "i = 0\n",
    "for group in panel_groups:\n",
    "    \n",
    "    # select all panels related to this group (INTA, ICA or IAS)\n",
    "    groups_select = list(panels_unique[panels_unique.str.contains(group)])\n",
    "    # sort from highest reflectance to lowest\n",
    "    groups_select.sort()\n",
    "    # intialize axis\n",
    "    ax = axes[i]\n",
    "    ax.set_title(f'{group} panels', fontsize=14)\n",
    "    ax.set_xlabel('Wavelength (nm)', fontsize=12)\n",
    "    ax.set_xlim(400, 900)\n",
    "    ax.set_ylabel('Reflectance (-)', fontsize=12)\n",
    "    ax.set_ylim(0, 1.2)\n",
    "    ax.grid(True)\n",
    "    \n",
    "    # create light to dark gradient depending on number of panels\n",
    "    color_gradient = np.linspace(0.8, 0, len(groups_select)).astype(str)\n",
    "    \n",
    "    # plot for each panel number\n",
    "    for n, g in enumerate(groups_select):\n",
    "      cols = id_panel[id_panel.str.contains(g)]\n",
    "      panel_number = asd_df[cols]\n",
    "        \n",
    "      # plot each of the spectra (each round)\n",
    "      for col in panel_number.columns:\n",
    "        ax.plot(wl_asd, panel_number[col].values, label=g, color=color_gradient[n])\n",
    "\n",
    "    # plot spectral response function\n",
    "    colormap = plt.cm.rainbow # Choose a colormap\n",
    "    colors = [colormap(x / (len(band_names) - 1)) for x in range(len(band_names))]\n",
    "    n = 0\n",
    "    for band in band_names:\n",
    "        ax.plot(srf_df['Wavelength_nm'], srf_df[band], color=colors[n], label = f'{str(band)}nm')\n",
    "        n = n + 1\n",
    "    # get mean ASD values convolved to Sequoia bands\n",
    "    for g in groups_select:\n",
    "        srf_mask = asd_convolved_df['panels'].str.contains(g)\n",
    "        convolved_values = asd_convolved_df[srf_mask]\n",
    "        j = 0\n",
    "        for band in band_names:\n",
    "            asd_band_values = np.mean(convolved_values[band])\n",
    "            ax.plot(sensor_band_center[j], asd_band_values, 'o', ms=6, c='black', mfc='deepskyblue')\n",
    "            j = j +1\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "# create legend for each subplot\n",
    "for ax in axes:\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    \n",
    "    # Create a dictionary to remove duplicates (preserves the first occurrence)\n",
    "    unique = dict(zip(labels, handles))\n",
    "    \n",
    "    # Add the legend with only the unique panel labels and color\n",
    "    ax.legend(unique.values(), unique.keys(), loc='upper left', ncols = len(groups_select))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4407338-fefa-42f8-bc34-ab2d57aa1cd5",
   "metadata": {},
   "source": [
    "# Extract UAV values over reference panels\n",
    "Here, we will use the centroid of each panel shapefile and extract values over a radius of 25x25cm\n",
    "\n",
    ":::{note}\n",
    "Different approaches can be applied to extract UAV data over panels. This is just an example, we can discuss if we should test other approaches\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318703e4-52ce-4b32-9d5a-3958720e9403",
   "metadata": {},
   "source": [
    "## Select which method you would use to extract the ASD information from the panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d03492c-305f-49d6-8deb-48f67975825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [('Centroid point', 'centroid'),\n",
    "           ('30cm buffer to centroid', 'centroid_buffer30cm'),\n",
    "           ('Borders polygon', \"borders\")\n",
    "         ]\n",
    "\n",
    "w_extraction =widgets.Dropdown(\n",
    "    options=methods,\n",
    "    value=\"centroid\",\n",
    "    description='Extraction method:',\n",
    ")\n",
    "\n",
    "display(w_extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ee49a7-e641-4c42-9f7c-51bce4937b77",
   "metadata": {},
   "source": [
    "### Visualize the geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033accb-1d05-45db-83e8-447ec6343c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shapefile directory\n",
    "vector_dir = datadir / 'dataset' / 'vector_data'\n",
    "\n",
    "print(f\"Reading the geometry from {w_extraction.label}\")\n",
    "# panel outline shaefile\n",
    "panels_file = vector_dir / f'panels_{w_extraction.value}.geojson'\n",
    "\n",
    "# open panel point shapefile as geopandas dataframe\n",
    "panels_gdf = gpd.read_file(panels_file)\n",
    "panels_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a44cd7-9d3a-476d-a581-40b0ddabb882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up output folder\n",
    "output_dir = Path(outdir) / f'{w_image.value}'\n",
    "\n",
    "# check if it already exists, if not created\n",
    "if not output_dir.exists():\n",
    "  output_dir.mkdir()\n",
    "\n",
    "\n",
    "no_data_value = 0\n",
    "# Choose which zonal statistics you want to extract: \"count min mean max median\"\n",
    "stat = \"mean\"\n",
    "uav_values_df = pd.DataFrame(columns=[\"panel_id\"])\n",
    "\n",
    "for b in range(num_bands):\n",
    "    # Define the name of the band\n",
    "    col_id = f'B{b+1}_{stat}'\n",
    "    # Extract zonal statistics using Raster Stats\n",
    "    extract_json = zonal_stats(panels_gdf, mosaic_file, band_num=(b+1), stats=stat, geojson_out=True, nodata=no_data_value)\n",
    "    # Loop along the panels extracted and create a table\n",
    "    panel_values = {\"panel_id\": [], col_id:[]}\n",
    "    for p in extract_json:\n",
    "        panel_name = p[\"properties\"][\"code\"]\n",
    "        panel_values[\"panel_id\"].append(panel_name)\n",
    "        if (w_image_type.value == 'Panels' and (sensor_name == 'Cubert' or (sensor_name == 'P4M' and sensor_group =='ICMAN'))):\n",
    "          panel_values[col_id].append(p[\"properties\"][stat]/10000)\n",
    "        else:\n",
    "          panel_values[col_id].append(p[\"properties\"][stat])\n",
    "\n",
    "    panel_values = pd.DataFrame(panel_values)\n",
    "    # Join tables\n",
    "    uav_values_df = pd.merge(uav_values_df, panel_values, on=\"panel_id\", how=\"outer\")\n",
    "\n",
    "# Saving extractions to a CSV file\n",
    "csv_output = output_dir / f'{w_image_type.value}_REF_{sensor_name}_{sensor_group}_{sensor_time}_{w_extraction.value}.csv'\n",
    "uav_values_df.to_csv(csv_output, index=False, sep=\";\")\n",
    "print(f\"Extractions saved in {csv_output}\")\n",
    "\n",
    "# Display table\n",
    "uav_values_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc65f7ff-a18c-43e6-b9af-85b639c5f62a",
   "metadata": {},
   "source": [
    "# Develop empirical line\n",
    "## Plot UAV vs ASD reflectance over reference panel\n",
    "\n",
    ":::{important}\n",
    "For now only testing with ASD measurements from Round 1 (R1).\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a69ff7-647e-460c-a075-e0db42764bbc",
   "metadata": {},
   "source": [
    "## Calibrating image reflectance \n",
    "\n",
    "We will calibrate the UAV images using the empirical line approach using the reference panels.\n",
    "\n",
    ":::{math}\n",
    "\\rho_{cal} = \\mathbf{gain} (\\rho_{original}) + \\mathbf{offset}\n",
    ":::\n",
    "\n",
    "When we have three or more references (e.g. panels), then we perform the calibration by fitting a linear regression model\n",
    "### Plot values over reference panels\n",
    "Scatter plot showing **uncalibrated UAV reflectance** vs **ASD measurements** over reference panels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf1a4a-da9a-4dfa-91c1-c4ee7418e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate color ramp based on number of bands in raster image\n",
    "colormap = plt.cm.rainbow # Choose a colormap\n",
    "colors = [colormap(x / (len(band_names) - 1)) for x in range(len(band_names))]\n",
    "\n",
    "# create 1x3 plot with each panel group\n",
    "fig, axes = plt.subplots(1,3, figsize=(14,4))\n",
    "i = 0\n",
    "for group in panel_groups:\n",
    "    # select all panels related to this group (INTA, ICA or IAS)\n",
    "    groups_select = list(panels_unique[panels_unique.str.contains(group)])\n",
    "    groups_select.sort()\n",
    "\n",
    "    # get asd data for particular group of pabels and round 1\n",
    "    asd_data = asd_convolved_df[asd_convolved_df['panels'].str.contains(group) & asd_convolved_df['panels'].str.contains('R1')]\n",
    "    # make sure panels sorted by lowest to highest\n",
    "    asd_data = asd_data.sort_values(by = ['panels'])\n",
    "    uav_data = uav_values_df[uav_values_df['panel_id'].str.contains(group)]\n",
    "    # make sure panels sorted by lowest to highest\n",
    "    uav_data = uav_data.sort_values(by = ['panel_id'])\n",
    "    # intialize axis\n",
    "    ax = axes[i]\n",
    "    b = 0\n",
    "    # plot for each band\n",
    "    for band in asd_data.columns[1:]:\n",
    "        asd_values = asd_data[band].values\n",
    "        #if w_image_type.value == 'Panels' and sensor_name == 'Cubert':\n",
    "        #  uav_values = uav_data[f'B{b+1}_{stat}'].values/10000\n",
    "        #else:\n",
    "        uav_values = uav_data[f'B{b+1}_{stat}'].values\n",
    "        ax.scatter(uav_values, asd_values, color=colors[b],label = f'{band}nm', marker='o')\n",
    "        b = b + 1\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.plot([0, 1.2], [0, 1.2], color='black', linestyle='--')\n",
    "    # only add band legend if dealing with multispectral data\n",
    "    if sensor_name != 'Cubert':\n",
    "      ax.legend()\n",
    "    # intialize axis\n",
    "    ax = axes[i]\n",
    "    ax.set_title(f'{group} panels', fontsize=14)\n",
    "    ax.set_xlabel('UAV Reflectance (-)', fontsize=12)\n",
    "    ax.set_xlim(0, 1.2)\n",
    "    ax.set_ylabel('ASD Reflectance (-)', fontsize=12)\n",
    "    ax.set_ylim(0, 1.2)\n",
    "    ax.grid(True)\n",
    "    i = i +1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6d1e6-5c53-4edd-a70a-f196eefdb89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dictonary to store of empirical model parameters\n",
    "lm_dict = {}\n",
    "\n",
    "for group in panel_groups:\n",
    "    # select all panels related to this group (INTA, ICA or IAS)\n",
    "    groups_select = list(panels_unique[panels_unique.str.contains(group)])\n",
    "    # get asd data for particular group of pabels and round 1\n",
    "    asd_data = asd_convolved_df[asd_convolved_df['panels'].str.contains(group) & asd_convolved_df['panels'].str.contains('R1')]\n",
    "    # make sure panels sorted by lowest to highest\n",
    "    asd_data = asd_data.sort_values(by = ['panels'])\n",
    "    uav_data = uav_values_df[uav_values_df['panel_id'].str.contains(group)]\n",
    "    # make sure panels sorted by lowest to highest\n",
    "    uav_data = uav_data.sort_values(by = ['panel_id'])\n",
    "\n",
    "    # initialize empty dictionary for each panel group to store results\n",
    "    lm_dict[group] = {}\n",
    "    # go through each band and develop linear model\n",
    "    b = 0\n",
    "    for band in asd_data.columns[1:]:\n",
    "        asd_values = asd_data[band].values\n",
    "        #if w_image_type.value == 'Panels' and sensor_name == 'Cubert':\n",
    "        #  uav_values = uav_data[f'B{b+1}_{stat}'].values/10000\n",
    "        #else:\n",
    "        uav_values = uav_data[f'B{b+1}_{stat}'].values\n",
    "        nan_mask = np.logical_and(asd_values>0, uav_values>0)\n",
    "        lm = linregress(uav_values[nan_mask], asd_values[nan_mask])\n",
    "        gain = lm.slope\n",
    "        offset = lm.intercept\n",
    "        r2 = lm.rvalue ** 2\n",
    "        # store result as list of [gain, offset, r2]\n",
    "        lm_dict[group][band] = [gain, offset, r2]\n",
    "        b = b + 1\n",
    "\n",
    "el_output = {}\n",
    "# convert dict to INTA panels\n",
    "inta_df = pd.DataFrame(lm_dict['INTA'])\n",
    "inta_df.index = ['gain', 'offset', 'R2']\n",
    "# convert dict to ICA panels\n",
    "ica_df = pd.DataFrame(lm_dict['ICA'])\n",
    "ica_df.index = ['gain', 'offset', 'R2']\n",
    "# convert dict to IAS panels\n",
    "ias_df = pd.DataFrame(lm_dict['IAS'])\n",
    "ias_df.index = ['gain', 'offset', 'R2']\n",
    "\n",
    "# Save the empirical line models to a json\n",
    "el_output[\"INTA\"] = inta_df.to_dict()\n",
    "el_output[\"ICA\"] = ica_df.to_dict()\n",
    "el_output[\"IAS\"] = ias_df.to_dict()\n",
    "\n",
    "# create output json file with fitted parameters\n",
    "el_outputfile = output_dir / f'{w_image_type.value}_REF_{sensor_name}_{sensor_group}_{sensor_time}_EL_{w_extraction.value}.json'\n",
    "with open(el_outputfile, \"w\") as outfile:\n",
    "    json.dump(el_output, outfile, indent=4)\n",
    "\n",
    "print(f\"Saved Empirical-Line coefficients to {el_outputfile}\")\n",
    "pd.DataFrame(el_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2d4cd-f3b2-428a-a35d-bd50ac519840",
   "metadata": {},
   "source": [
    "### Visualize linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59825cf-bf16-45d3-9e96-2b5b6b3d616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = plt.cm.rainbow # Choose a colormap\n",
    "colors = [colormap(x / (len(band_names) - 1)) for x in range(len(band_names))]\n",
    "\n",
    "# create 1x3 plot with each panel group\n",
    "fig, axes = plt.subplots(1,3, figsize=(14,4))\n",
    "i = 0\n",
    "for group in panel_groups:\n",
    "    # get linear model parameters associated to each group\n",
    "    lm_panels = lm_dict[group]\n",
    "\n",
    "    # select all panels related to this group (INTA, ICA or IAS)\n",
    "    groups_select = list(panels_unique[panels_unique.str.contains(group)])\n",
    "    # get asd data for particular group of panels and round 1\n",
    "    asd_data = asd_convolved_df[asd_convolved_df['panels'].str.contains(group) & asd_convolved_df['panels'].str.contains('R1')]\n",
    "    # make sure panels sorted by lowest to highest\n",
    "    asd_data = asd_data.sort_values(by = ['panels'])\n",
    "    uav_data = uav_values_df[uav_values_df['panel_id'].str.contains(group)]\n",
    "    # make sure panels sorted by lowest to highest\n",
    "    uav_data = uav_data.sort_values(by = ['panel_id'])\n",
    "    # intialize axis\n",
    "    ax = axes[i]\n",
    "    b = 0\n",
    "    for band in asd_data.columns[1:]:\n",
    "        asd_values = asd_data[band].values\n",
    "        #if w_image_type.value == 'Panels' and sensor_name == 'Cubert':\n",
    "        #  uav_values = uav_data[f'B{b+1}_{stat}'].values/10000\n",
    "        #else:\n",
    "        uav_values = uav_data[f'B{b+1}_{stat}'].values\n",
    "        # get lm params\n",
    "        gain = lm_panels[band][0]\n",
    "        offset = lm_panels[band][1]\n",
    "        r2 = lm_panels[band][2]\n",
    "        # plot linear regression\n",
    "        x_lm = (np.nanmin(uav_values), np.nanmax(uav_values))\n",
    "        y_lm = (gain*np.nanmin(uav_values) + offset, gain*np.nanmax(uav_values)+offset)\n",
    "        ax.plot(x_lm, y_lm, color=colors[b], linestyle = '--')\n",
    "        ax.scatter(uav_values, asd_values, color=colors[b],label = f'{band}nm, $R^2$ = {np.round(r2,3)}', marker='o')\n",
    "\n",
    "        b = b + 1\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.plot([0, 1.2], [0, 1.2], color='black', linestyle='--')\n",
    "    # only show legend if dealing with multispectral data\n",
    "    if sensor_name != 'Cubert':\n",
    "      ax.legend(fontsize=8)\n",
    "    # intialize axis\n",
    "    ax = axes[i]\n",
    "    ax.set_title(f'{group} panels', fontsize=14)\n",
    "    ax.set_xlabel('UAV Reflectance (-)', fontsize=12)\n",
    "    ax.set_xlim(0, 1.2)\n",
    "    ax.set_ylabel('ASD Reflectance (-)', fontsize=12)\n",
    "    ax.set_ylim(0, 1.2)\n",
    "    ax.grid(True)\n",
    "    i = i +1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcac314-5c0d-4331-810a-342c6b7cddc0",
   "metadata": {},
   "source": [
    "# Calibrate image with developed empirical model\n",
    "\n",
    "Apply developed empirical line on each band of UAV image.\n",
    "> **Note**: depending on image size and number of bands, this may take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65aaabe-5670-4b5f-8a72-891ef88d84d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open uav image as gdal object\n",
    "fid = gdal.Open(str(mosaic_file))\n",
    "\n",
    "# get geotransform data\n",
    "geotransform = fid.GetGeoTransform()\n",
    "proj = fid.GetProjection()\n",
    "minx, maxy = geotransform[0], geotransform[3]\n",
    "maxx = minx + geotransform[1] * fid.RasterXSize\n",
    "miny = maxy + geotransform[5] * fid.RasterYSize\n",
    "\n",
    "# get metadata of image\n",
    "num_bands = fid.RasterCount\n",
    "template_ar = fid.GetRasterBand(1).ReadAsArray()\n",
    "rows, cols = template_ar.shape\n",
    "\n",
    "# initialize empty 3D array with same number of bands\n",
    "ar_inta_cal = np.full((rows, cols, num_bands), np.nan)\n",
    "ar_ica_cal = np.full((rows, cols, num_bands), np.nan)\n",
    "ar_ias_cal = np.full((rows, cols, num_bands), np.nan)\n",
    "\n",
    "\n",
    "for band in range(num_bands):\n",
    "    print(f'- calibrating {sensor_name} Band {band+1}...')\n",
    "    if (w_image_type.value == 'Panels' and (sensor_name == 'Cubert' or (sensor_name == 'P4M' and sensor_group =='ICMAN'))):\n",
    "    #if w_image_type.value == 'Panels' and sensor_name == 'Cubert':\n",
    "      ar = fid.GetRasterBand(band+1).ReadAsArray()/10000\n",
    "    else:\n",
    "      ar = fid.GetRasterBand(band+1).ReadAsArray()\n",
    "\n",
    "    # get band name in string\n",
    "    band_name = band_names[band]\n",
    "    # inta LM/EL parameters\n",
    "    gain, offset = lm_dict['INTA'][band_name][:2]\n",
    "    # calibrate based on INTA reference panels\n",
    "    ar_inta_cal[:,:,band] = (gain*ar) + offset\n",
    "    # ica LM/EL parameters\n",
    "    gain, offset = lm_dict['ICA'][band_name][:2]\n",
    "    # calibrate based on ICA reference panels\n",
    "    ar_ica_cal[:,:,band] = (gain*ar) + offset\n",
    "    # ias LM/EL parameters\n",
    "    gain, offset = lm_dict['IAS'][band_name][:2]\n",
    "    # calibrate based on IAS reference panels\n",
    "    ar_ias_cal[:,:,band] = (gain*ar) + offset\n",
    "\n",
    "# save calibrated images as geotiffs\n",
    "for group in panel_groups:\n",
    "    outfilename = f'{w_image_type.value}_REF_{sensor_name}_{sensor_group}_{sensor_time}_EL_{group}panels_{w_extraction.value}.tif'\n",
    "    outfile = output_dir / outfilename\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    nbands = ar_inta_cal.shape[2]\n",
    "    print(f'- saving image calibrated with {group} panels...')\n",
    "    ds = driver.Create(str(outfile), cols, rows, nbands, gdal.GDT_Float32)\n",
    "    ds.SetGeoTransform(geotransform)\n",
    "    ds.SetProjection(proj)\n",
    "    input_nodata = np.nan\n",
    "    if group == 'INTA':\n",
    "        ar_img = ar_inta_cal\n",
    "    elif group == 'ICA':\n",
    "        ar_img = ar_ica_cal\n",
    "    else:\n",
    "        ar_img = ar_ias_cal\n",
    "\n",
    "    for i in range(nbands):\n",
    "        band = ds.GetRasterBand(i+1)\n",
    "        band.SetNoDataValue(input_nodata)\n",
    "        array = ar_img[:,:,i]\n",
    "        array[np.isnan(array)] = input_nodata\n",
    "        band.WriteArray(array)\n",
    "        band.FlushCache()\n",
    "\n",
    "    ds.FlushCache()\n",
    "    ds = None\n",
    "    print(f'Calibrated image using {group} panels saved as {str(outfile)}')\n",
    "gc.collect()\n",
    "del fid\n",
    "del ar_inta_cal, ar_ica_cal, ar_ias_cal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754d6038-8367-4797-ad76-f0eddb013d80",
   "metadata": {},
   "source": [
    "## Evaluate calibrated images against ASD data \n",
    "### extract calibrated UAV data over reference panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d146f85-0d51-4589-8278-51e56e82d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uav_cal_values_df = pd.DataFrame(columns=[\"panel_id\"])\n",
    "\n",
    "for group in panel_groups:\n",
    "    # get calibrated images\n",
    "    img_file = output_dir / f'{w_image_type.value}_REF_{sensor_name}_{sensor_group}_{sensor_time}_EL_{group}panels_{w_extraction.value}.tif'\n",
    "    for b in range(num_bands):\n",
    "        # Define the name of the band\n",
    "        col_id = f'B{b+1}_{group}'\n",
    "        print(f'Band {b+1} {group} panels')\n",
    "        # Extract zonal statistics using Raster Stats\n",
    "        extract_json = zonal_stats(panels_gdf, img_file, band_num=(b+1), stats=stat, geojson_out=True)\n",
    "        # Loop along the panels extracted and create a table\n",
    "        panel_values = {\"panel_id\": [], col_id:[]}\n",
    "        for p in extract_json:\n",
    "            panel_name = p[\"properties\"][\"code\"]\n",
    "            panel_values[\"panel_id\"].append(panel_name)\n",
    "            panel_values[col_id].append(p[\"properties\"][stat])\n",
    "\n",
    "        panel_values = pd.DataFrame(panel_values)\n",
    "        # Join tables\n",
    "        uav_cal_values_df = pd.merge(uav_cal_values_df, panel_values, on=\"panel_id\", how=\"outer\")\n",
    "\n",
    "# Save the extractions to a CSV table\n",
    "csv_output = output_dir / f'{w_image_type}_REF_{sensor_name}_{sensor_group}_{sensor_time}_EL_{w_extraction.value}.csv'\n",
    "uav_cal_values_df.to_csv(csv_output, index=False, sep=\";\")\n",
    "print(f\"Empirical-line Extractions saved to {csv_output}\")\n",
    "\n",
    "# Display the extractions\n",
    "uav_cal_values_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88db7ca-1e35-4196-9517-9fe044dbbaeb",
   "metadata": {},
   "source": [
    "### Plot calibrated UAV reflectance against ASD data\n",
    "\n",
    "Compare calibrated UAV reflectance against ASD measurements. We will also save error metrics (RMSE, R2, bias) into a csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213556ab-587e-4ca5-8727-3fc9055ee5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate model performance metrics\n",
    "def error_metrics(X, Y):\n",
    "    rmse = np.sqrt(np.nanmean((X - Y) ** 2))\n",
    "    cor = st.pearsonr(X[np.logical_and(~np.isnan(X),~np.isnan(Y))],\n",
    "                      Y[np.logical_and(~np.isnan(Y),~np.isnan(X))])[0]\n",
    "    r2 = cor ** 2\n",
    "    bias = np.nanmean(X - Y)\n",
    "    return rmse, r2, bias\n",
    "\n",
    "# define colormap depending on number of bands\n",
    "colormap = plt.cm.rainbow # Choose a colormap\n",
    "colors = [colormap(x / (len(band_names) - 1)) for x in range(len(band_names))]\n",
    "\n",
    "# initialize output dataframe\n",
    "results_df = pd.DataFrame(columns=[\"bands\"])\n",
    "\n",
    "\n",
    "# create 1x3 plot with each panel group\n",
    "fig, axes = plt.subplots(3,2, figsize=(14,18))\n",
    "i = 0\n",
    "for group in panel_groups:\n",
    "    # select all panels related to this group (INTA, ICA or IAS)\n",
    "    groups_select = list(panels_unique[panels_unique.str.contains(group)])\n",
    "    # get asd data for particular group of pabels and round 1\n",
    "    asd_data = asd_convolved_df[asd_convolved_df['panels'].str.contains(group) & asd_convolved_df['panels'].str.contains('R1')]\n",
    "    asd_data = asd_data.sort_values(by = ['panels'])\n",
    "    # original UAV data over panels\n",
    "    uav_data = uav_values_df[uav_values_df['panel_id'].str.contains(group)]\n",
    "    uav_data = uav_data.sort_values(by = ['panel_id'])\n",
    "\n",
    "    # calibrated UAV data over panels\n",
    "    cal_data = uav_cal_values_df[uav_cal_values_df['panel_id'].str.contains(group)]\n",
    "    cal_data = cal_data.sort_values(by = ['panel_id'])\n",
    "\n",
    "    # intialize axis\n",
    "    ax = axes[i,0]\n",
    "    b = 0\n",
    "    rmse_og = []\n",
    "\n",
    "    # output columns\n",
    "    rmse_id = f'orig_{group}_rmse'\n",
    "    r2_id = f'orig_{group}_R2'\n",
    "    bias_id = f'orig_{group}_bias'\n",
    "    # initialize output dict\n",
    "    band_metrics = {\"bands\": [], rmse_id:[], r2_id:[], bias_id:[]}\n",
    "\n",
    "    for band in asd_data.columns[1:]:\n",
    "        band_metrics['bands'].append(band)\n",
    "        asd_values = asd_data[band].values\n",
    "        uav_values = uav_data[f'B{b+1}_{stat}'].values\n",
    "        nan_mask = np.logical_and(asd_values > 0, uav_values > 0)\n",
    "        rmse, r2, bias = error_metrics(asd_values[nan_mask], uav_values[nan_mask])\n",
    "        band_metrics[rmse_id].append(rmse)\n",
    "        band_metrics[r2_id].append(r2)\n",
    "        band_metrics[bias_id].append(bias)\n",
    "        rmse_og.append(rmse)\n",
    "        ax.scatter(uav_values, asd_values, color=colors[b],label = f'{band}nm, rmse = {np.round(rmse,3)}', marker='o')\n",
    "        b = b + 1\n",
    "    # get mean rmse for all bands\n",
    "    rmse_og_mean = np.nanmean(rmse_og)\n",
    "    band_metrics_df = pd.DataFrame(band_metrics)\n",
    "    # Join tables\n",
    "    results_df = pd.merge(results_df, band_metrics_df, on=\"bands\", how=\"outer\")\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.plot([0, 1.2], [0, 1.2], color='black', linestyle='--')\n",
    "    ax.text(0.75, 0.7, f'RMSE(mean) = {np.round(rmse_og_mean,4)}', weight='bold')\n",
    "\n",
    "    if sensor_name != 'Cubert':\n",
    "      ax.legend()\n",
    "    ax.set_title(f'{group} panels - Original', fontsize=14)\n",
    "    ax.set_xlabel('UAV Reflectance (-)', fontsize=12)\n",
    "    ax.set_xlim(0, 1.2)\n",
    "    ax.set_ylabel('ASD Reflectance (-)', fontsize=12)\n",
    "    ax.set_ylim(0, 1.2)\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax2 = axes[i,1]\n",
    "    b = 0\n",
    "    rmse_cal = []\n",
    "\n",
    "    # output column\n",
    "    rmse_id = f'EL_{group}_rmse'\n",
    "    r2_id = f'EL_{group}_R2'\n",
    "    bias_id = f'EL_{group}_bias'\n",
    "\n",
    "    band_metrics = {\"bands\": [], rmse_id:[], r2_id:[], bias_id:[]}\n",
    "    for band in asd_data.columns[1:]:\n",
    "        band_metrics['bands'].append(band)\n",
    "        asd_values = asd_data[band].values\n",
    "        cal_values = cal_data[f'B{b+1}_{group}'].values\n",
    "        rmse, r2, bias = error_metrics(asd_values, cal_values)\n",
    "        band_metrics[rmse_id].append(rmse)\n",
    "        band_metrics[r2_id].append(r2)\n",
    "        band_metrics[bias_id].append(bias)\n",
    "        rmse_cal.append(rmse)\n",
    "        ax2.scatter(cal_values, asd_values, color=colors[b],label = f'{band}nm, rmse = {np.round(rmse,3)}', marker='o')\n",
    "\n",
    "        b = b + 1\n",
    "    # get mean rmse for all bands\n",
    "    rmse_cal_mean = np.nanmean(rmse_cal)\n",
    "    band_metrics_df = pd.DataFrame(band_metrics)\n",
    "    # Join tables\n",
    "    results_df = pd.merge(results_df, band_metrics_df, on=\"bands\", how=\"outer\")\n",
    "\n",
    "    ax2.grid(True)\n",
    "    ax2.plot([-0.2, 1.2], [-0.2, 1.2], color='black', linestyle='--')\n",
    "    ax2.text(0.75, 0.7, f'RMSE(mean) = {np.round(rmse_cal_mean,4)}', weight='bold')\n",
    "    if sensor_name != 'Cubert':\n",
    "      ax2.legend()\n",
    "    ax2.set_title(f'{group} panels - Calibrated', fontsize=14)\n",
    "    ax2.set_xlabel('UAV Reflectance (-)', fontsize=12)\n",
    "    ax2.set_xlim(0, 1.2)\n",
    "    ax2.set_ylabel('ASD Reflectance (-)', fontsize=12)\n",
    "    ax2.set_ylim(0, 1.2)\n",
    "    ax2.grid(True)\n",
    "    i = i +1\n",
    "plt.show()\n",
    "# Save the model metric results to a CSV table\n",
    "csv_output = output_dir / f'Results_{sensor_name}_{sensor_group}_{sensor_time}_REF_{w_extraction.value}.csv'\n",
    "results_df.to_csv(csv_output, index=False, sep=\";\")\n",
    "print(f\"Model metric results saved to {csv_output}\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338b6000-f5aa-4501-a96a-a8b73423c515",
   "metadata": {},
   "source": [
    "# Next Steps?\n",
    "\n",
    "- evaluate different sensor types (TIR)\n",
    "- individual tile vs orthomosaic\n",
    "- homogeneity analysis of panels\n",
    "- best method to extract UAV data over panels? Radius (square, circle)? what size?\n",
    "- timing of ASD measurements (round 1 vs round 2 vs round 3)\n",
    "- number of panels to use?\n",
    "- other??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
